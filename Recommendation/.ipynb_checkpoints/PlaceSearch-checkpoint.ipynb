{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import date,timedelta,datetime\n",
    "import pandas_gbq\n",
    "from google.oauth2 import service_account\n",
    "from fuzzywuzzy import fuzz\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Update twitter data, it run more than 2 hours, so please do not run it. It will check current time - previous_update_time first.\n",
    "# %run twitter/twitter_attractions.ipynb\n",
    "\n",
    "key = \"...\"\n",
    "dataset = 'finalproject'\n",
    "project_id = '...'\n",
    "# table = \"testHotel\"\n",
    "\n",
    "food_lst = [\"bakery\",\"bar\",\"cafe\",\"restaurant\", \"meal_takeaway\"]\n",
    "play_lst = [\"library\", \"museum\", \"park\", \"shopping_mall\", \"zoo\"]\n",
    "searchType = [\"Hotel\", \"Food\", \"Play\"]\n",
    "\n",
    "rapidapi_host = \"hotels4.p.rapidapi.com\"\n",
    "rapidapi_key =  \"...\"\n",
    "\n",
    "#\"46facb3d8dmshb5e20b5bc84b439p1a9646jsn7b49c8952c8d\"\n",
    "credentials = service_account.Credentials.from_service_account_info(\n",
    "    {\n",
    "   \"type\": \"service_account\",\n",
    "  \"project_id\": \"...\",\n",
    "  \"private_key_id\": \"...\",\n",
    "  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\n...\\n-----END PRIVATE KEY-----\\n\",\n",
    "  \"client_email\": \"....iam.gserviceaccount.com\",\n",
    "  \"client_id\": \"...\",\n",
    "  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
    "  \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
    "  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
    "  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/...\"\n",
    "  },)\n",
    "\n",
    "current_path = os.path.abspath(os.getcwd())\n",
    "crime_path = current_path + \"/crimedata/analysis/zipcode_saftylevel.csv\"\n",
    "twitter_path = current_path + \"/twitter/attractions.csv\"\n",
    "no_hotel_path =  current_path + \"/Recommendation/no_hotel.txt\"\n",
    "\n",
    "\n",
    "tmp_file = open(no_hotel_path, \"r\")\n",
    "tmp_cont = tmp_file.read()\n",
    "no_hotel_lst = tmp_cont.strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHotelID(response,hotel_name,geo_pair):\n",
    "  total = response.json()\n",
    "  # print(total, hotel_name, geo_pair)\n",
    "  total = total[\"suggestions\"]\n",
    "  hotel = [e for e in total if e['group']=='HOTEL_GROUP'][0]\n",
    "  Find = False\n",
    "  if len(hotel[\"entities\"]) == 0:\n",
    "#     print(\"Can't find hotel when name: \", hotel_name)\n",
    "    no_hotel_lst.append(hotel_name)\n",
    "    hotel_info = pd.DataFrame()\n",
    "    return Find, hotel_info\n",
    "  all_hotel = hotel[\"entities\"]\n",
    "  ID = []\n",
    "  name = []\n",
    "  geometric = []\n",
    "  for h in all_hotel:\n",
    "    ID.append(h[\"destinationId\"])\n",
    "    name.append(h[\"name\"])\n",
    "    geometric.append((float(\"{:.3f}\".format(h[\"latitude\"])),float(\"{:.3f}\".format(h[\"longitude\"]))))\n",
    "    if h[\"name\"] == hotel_name or geometric[-1] == geo_pair:\n",
    "      Find = True\n",
    "  hotel_info = pd.DataFrame({\"ID\":ID, \"name\":name, \"geometric\": geometric})\n",
    "  return Find, hotel_info\n",
    "\n",
    "def getHotelPrice(total,hotel_name):\n",
    "  #total = response.json()[\"price\"]\n",
    "  try:\n",
    "    rooms = total[\"body\"][\"roomsAndRates\"][\"rooms\"]\n",
    "    room_name = []\n",
    "    pricelst=[]\n",
    "    h_name = []\n",
    "    for room in rooms:\n",
    "      n = room[\"name\"]\n",
    "      price = room[\"ratePlans\"][0][\"price\"]['fullyBundledPricePerStay']\n",
    "      h_name.append(hotel_name)\n",
    "      room_name.append(n)\n",
    "      pricelst.append(price)\n",
    "    price_df = pd.DataFrame({\"name\": h_name,\"Room_type\":room_name,\"Price\":pricelst})\n",
    "    return price_df\n",
    "  except:\n",
    "    return pd.DataFrame()\n",
    "\n",
    "def getresponse(hotel_name):\n",
    "\n",
    "  url = \"https://hotels4.p.rapidapi.com/locations/v2/search\"\n",
    "\n",
    "  querystring = {\"query\":\"New York,\"+hotel_name,\"locale\":\"en_US\",\"currency\":\"USD\"}\n",
    "  headers = {\n",
    "      'x-rapidapi-host': rapidapi_host,\n",
    "      'x-rapidapi-key': rapidapi_key\n",
    "      }\n",
    "\n",
    "  response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "  return response\n",
    "\n",
    "def getresponse2(id,checkIn, checkOut):\n",
    "\n",
    "  url = \"https://hotels4.p.rapidapi.com/properties/get-details\"\n",
    "\n",
    "  querystring = {\"id\":id,\"checkIn\":checkIn,\"checkOut\":checkOut,\"adults1\":\"1\",\"currency\":\"USD\",\"locale\":\"en_US\"}\n",
    "\n",
    "  headers = {\n",
    "      'x-rapidapi-host': rapidapi_host,\n",
    "      'x-rapidapi-key': rapidapi_key\n",
    "      }\n",
    "\n",
    "  response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "  return response\n",
    "\n",
    "def Zip2Loc(zip):\n",
    "  \"\"\"convert zipcode to lat ang lng\"\"\"\n",
    "  # Input:\n",
    "  # zip: string or int, key: string\n",
    "  # Output:\n",
    "  # location dictionary: {\"lat\":float, \"lng\":float}\n",
    "  url = 'https://maps.googleapis.com/maps/api/geocode/json?address='+str(zip)+'&key='+key\n",
    "  response = requests.get(url)\n",
    "  resp_json_payload = response.json()\n",
    "  return resp_json_payload['results'][0]['geometry']['location']\n",
    "\n",
    "def searchLodging(zip,r):\n",
    "  # r: radious (meters)\n",
    "  loc = Zip2Loc(zip)\n",
    "  url = \"https://maps.googleapis.com/maps/api/place/textsearch/json?location=\"+\\\n",
    "          str(loc[\"lat\"])+\"%2C\"+str(loc[\"lng\"])+\"&radius=\"+\\\n",
    "          str(r)+\"&type=lodging&hasNextPage=true&nextPage()=true&sensor=false&key=\"+key\n",
    "  response = requests.get(url)\n",
    "  resp_json_payload = response.json()\n",
    "  df = pd.json_normalize(resp_json_payload[\"results\"])\n",
    "  while \"next_page_token\" in resp_json_payload:\n",
    "    time.sleep(3)\n",
    "    page2_token = resp_json_payload[\"next_page_token\"]        \n",
    "    url=\"https://maps.googleapis.com/maps/api/place/textsearch/json?location=\"+\\\n",
    "          str(loc[\"lat\"])+\"%2C\"+str(loc[\"lng\"])+\"&radius=\"+\\\n",
    "          str(r)+\"&type=lodging&pagetoken=\"+page2_token+\"&key=\"+key\n",
    "    response = requests.get(url)\n",
    "    resp_json_payload = response.json()\n",
    "\n",
    "    df2 = pd.json_normalize(resp_json_payload[\"results\"])\n",
    "    df = pd.concat([df,df2])\n",
    "\n",
    "  df = df.drop_duplicates(\"place_id\")\n",
    "  new_col = [name.replace(\".\",\"_\") for name in list(df.columns)]\n",
    "  df.set_axis(new_col,axis = 1, inplace = True)\n",
    "  return df\n",
    "  # return df.drop_duplicates(\"place_id\")\n",
    "\n",
    "def getID(zip,r):\n",
    "  try:\n",
    "    query = \"SELECT * FROM `\"+dataset+\".hotel_info`\"\n",
    "    hotel_info = pandas_gbq.read_gbq(\n",
    "    query,\n",
    "    project_id=project_id,credentials=credentials)\n",
    "#     hotel_info = pandas_gbq.read_gbq(\n",
    "#     \"SELECT * FROM `finalproject.hotel_info`\",\n",
    "#     project_id=project_id,credentials=credentials)\n",
    "\n",
    "    hotel_info[\"name\"] = [re.sub('[^a-zA-Z0-9 \\n\\.]', ' ', name) for name in hotel_info[\"name\"]]\n",
    "\n",
    "  except:\n",
    "#     print(\"create new hotel info\")\n",
    "    hotel_info = pd.DataFrame()\n",
    "\n",
    "  df = searchLodging(zip,r)\n",
    "  df[\"geoID\"] = [\"None\" for _ in range(len(df))]\n",
    "\n",
    "  for i in range(len(df)):\n",
    "    element = df.iloc[i]\n",
    "    h_name = re.sub('[^a-zA-Z0-9 \\n\\.]', ' ', element[\"name\"])\n",
    "    h_geo = (float(\"{:.3f}\".format(element[\"geometry_location_lat\"])), float(\"{:.3f}\".format(element[\"geometry_location_lng\"])))\n",
    "    # print(h_name,h_geo)\n",
    "    if hotel_info.empty:\n",
    "#       print(\"Empty hotel info: use Hotel API Get hotel ID\")\n",
    "      if h_name in no_hotel_lst:\n",
    "        continue\n",
    "      response = getresponse(h_name)\n",
    "      Find, new_hotel_info = getHotelID(response,h_name,h_geo)\n",
    "      if Find:\n",
    "        if h_name in list(new_hotel_info[\"name\"]):\n",
    "          df[\"geoID\"].iloc[i] = new_hotel_info[new_hotel_info[\"name\"] == h_name][\"ID\"].iloc[0]\n",
    "        elif h_geo in list(new_hotel_info[\"geometric\"]):\n",
    "\n",
    "          geo_lst = new_hotel_info[new_hotel_info[\"geometric\"] == h_geo]\n",
    "          max_score = 0\n",
    "          max_ID = None\n",
    "          for geo in geo_lst:\n",
    "            ratio = fuzz.token_sort_ratio(geo[\"name\"],h_name)\n",
    "            if ratio>max_score:\n",
    "              max_ID = geo[\"ID\"]\n",
    "              max_score = ratio\n",
    "\n",
    "          if max_score>=85:\n",
    "            df[\"geoID\"].iloc[i] = max_ID\n",
    "          else:\n",
    "            no_hotel_lst.append(h_name)\n",
    "            \n",
    "          # df[\"geoID\"].iloc[i]= new_hotel_info[new_hotel_info[\"geometric\"] == h_geo][\"ID\"].iloc[0]\n",
    "      if new_hotel_info.empty:\n",
    "        continue\n",
    "      hotel_info = new_hotel_info\n",
    "    else:\n",
    "      # print(\"have hotel\")\n",
    "      str_geo = str(h_geo)\n",
    "#       print(h_name, str_geo)\n",
    "      if h_name in list(hotel_info[\"name\"]):\n",
    "        # print(\"Find same name\")\n",
    "        df[\"geoID\"].iloc[i] = hotel_info[hotel_info[\"name\"] == h_name][\"ID\"].iloc[0]\n",
    "      elif str_geo in list(hotel_info[\"geometric\"]):\n",
    "        # print(\"Find same geo\")\n",
    "          geo_lst = hotel_info[hotel_info[\"geometric\"] == str_geo]\n",
    "          max_score = 0\n",
    "          max_ID = None\n",
    "          for geo in range(len(geo_lst)):\n",
    "#             print(geo_lst.iloc[geo][\"name\"],h_name)\n",
    "            ratio = fuzz.token_sort_ratio(geo_lst.iloc[geo][\"name\"],h_name)\n",
    "            if ratio>max_score:\n",
    "              max_ID = geo_lst.iloc[geo][\"ID\"]\n",
    "              max_score = ratio\n",
    "\n",
    "          if max_score>=85:\n",
    "            df[\"geoID\"].iloc[i] = max_ID\n",
    "        # df[\"geoID\"].iloc[i] = hotel_info[hotel_info[\"geometric\"] == h_geo][\"ID\"].iloc[0]\n",
    "      elif h_name not in no_hotel_lst:\n",
    "#         print(\"use Hotel API Get hotel ID\", h_name)\n",
    "        # break\n",
    "        response = getresponse(h_name)\n",
    "        Find, new_hotel_info = getHotelID(response,h_name,h_geo)\n",
    "        # print(Find, type(new_hotel_info.iloc[0][\"geometric\"]))\n",
    "        # break\n",
    "        if Find:\n",
    "          if (h_name in list(new_hotel_info[\"name\"])):\n",
    "            df[\"geoID\"].iloc[i] = new_hotel_info[new_hotel_info[\"name\"] == h_name][\"ID\"].iloc[0]\n",
    "          elif h_geo in list(new_hotel_info[\"geometric\"]):\n",
    "\n",
    "            geo_lst = new_hotel_info[new_hotel_info[\"geometric\"] == h_geo]\n",
    "            max_score = 0\n",
    "            max_ID = None\n",
    "            for geo in range(len(geo_lst)):\n",
    "#               print(geo_lst.iloc[geo][\"name\"],h_name)\n",
    "              ratio = fuzz.token_sort_ratio(geo_lst.iloc[geo][\"name\"],h_name)\n",
    "              if ratio>max_score:\n",
    "                max_ID = geo_lst.iloc[geo][\"ID\"]\n",
    "                max_score = ratio\n",
    "\n",
    "            if max_score>=85:\n",
    "              df[\"geoID\"].iloc[i] = max_ID\n",
    "            else:\n",
    "              no_hotel_lst.append(h_name)\n",
    "\n",
    "            # df[\"geoID\"].iloc[i] = new_hotel_info[new_hotel_info[\"geometric\"] == h_geo][\"ID\"].iloc[0]\n",
    "        if new_hotel_info.empty:\n",
    "          continue\n",
    "        hotel_info = pd.concat([hotel_info, new_hotel_info]).drop_duplicates(\"name\")\n",
    "  return df, hotel_info\n",
    "\n",
    "def getAllPrice(df,checkIn, checkOut):\n",
    "  price_table = dataset+\".HotelPrice_\"+checkIn\n",
    "  query = \"SELECT * FROM `\"+price_table+\"`\"\n",
    "  try:\n",
    "    price_df = pandas_gbq.read_gbq(\n",
    "    query,\n",
    "    project_id=project_id,credentials = credentials)\n",
    "#     print(\"In get all price2\")\n",
    "  except:\n",
    "#     print(\"In get all price3\")\n",
    "    price_df = pd.DataFrame()\n",
    "  for i in range(len(df)):\n",
    "    element = df.iloc[i]\n",
    "    h_id = element[\"geoID\"]\n",
    "\n",
    "    if h_id == \"None\":\n",
    "      continue\n",
    "    h_name = element[\"name\"]\n",
    "    if price_df.empty:\n",
    "#       print(\"use Hotel API\")\n",
    "      response = getresponse2(h_id, checkIn, checkOut)\n",
    "#       print(response)\n",
    "      try:\n",
    "        total = response.json()[\"data\"]\n",
    "      except:\n",
    "        break\n",
    "        # continue\n",
    "      tmp_price = getHotelPrice(total,h_name)\n",
    "      # if price_df.empty:\n",
    "      price_df = tmp_price\n",
    "      # else:\n",
    "      #   price_df = pd.concat([price_df, tmp_price])\n",
    "    else:\n",
    "      if h_name in list(price_df[\"name\"]):\n",
    "        continue\n",
    "      else:\n",
    "#         print(\"use hotel API\")\n",
    "        response = getresponse2(h_id, checkIn, checkOut)\n",
    "        try:\n",
    "          total = response.json()[\"data\"]\n",
    "#           print(\"get data\")\n",
    "        except:\n",
    "#           print(\"don't get price\", response)\n",
    "          continue\n",
    "        tmp_price = getHotelPrice(total,h_name)\n",
    "        if tmp_price.empty:\n",
    "          continue\n",
    "        price_df = pd.concat([price_df, tmp_price])\n",
    "\n",
    "  # print(price_df)\n",
    "\n",
    "  return price_df\n",
    "\n",
    "def searchFood(zip,r):\n",
    "  loc = Zip2Loc(zip)\n",
    "  df = pd.DataFrame()\n",
    "  for food in food_lst:\n",
    "    url = \"https://maps.googleapis.com/maps/api/place/textsearch/json?location=\"+\\\n",
    "            str(loc[\"lat\"])+\"%2C\"+str(loc[\"lng\"])+\"&radius=\"+\\\n",
    "            str(r)+\"&type=\"+food+\"&hasNextPage=true&nextPage()=true&sensor=false&key=\"+key\n",
    "    response = requests.get(url)\n",
    "    resp_json_payload = response.json()\n",
    "    if df.empty:\n",
    "      df = pd.json_normalize(resp_json_payload[\"results\"])  \n",
    "    else:\n",
    "      df2 = pd.json_normalize(resp_json_payload[\"results\"])\n",
    "      df = pd.concat([df,df2])\n",
    "    while \"next_page_token\" in resp_json_payload:\n",
    "      time.sleep(3)\n",
    "      page2_token = resp_json_payload[\"next_page_token\"]        \n",
    "      url=\"https://maps.googleapis.com/maps/api/place/textsearch/json?location=\"+\\\n",
    "          str(loc[\"lat\"])+\"%2C\"+str(loc[\"lng\"])+\"&radius=\"+\\\n",
    "          str(r)+\"&type=\"+food+\"&pagetoken=\"+page2_token+\"&key=\"+key\n",
    "      response = requests.get(url)\n",
    "      resp_json_payload = response.json()\n",
    "\n",
    "      df2 = pd.json_normalize(resp_json_payload[\"results\"])\n",
    "      df = pd.concat([df,df2])\n",
    "  return df.drop_duplicates(\"place_id\")\n",
    "\n",
    "def searchPlay(zip,r):\n",
    "  loc = Zip2Loc(zip)\n",
    "  df = pd.DataFrame()\n",
    "  for place in play_lst:\n",
    "    url = \"https://maps.googleapis.com/maps/api/place/textsearch/json?location=\"+\\\n",
    "            str(loc[\"lat\"])+\"%2C\"+str(loc[\"lng\"])+\"&radius=\"+\\\n",
    "            str(r)+\"&type=\"+place+\"&hasNextPage=true&nextPage()=true&sensor=false&key=\"+key\n",
    "    response = requests.get(url)\n",
    "    resp_json_payload = response.json()\n",
    "    if df.empty:\n",
    "      df = pd.json_normalize(resp_json_payload[\"results\"])  \n",
    "    else:\n",
    "      df2 = pd.json_normalize(resp_json_payload[\"results\"])\n",
    "      df = pd.concat([df,df2])\n",
    "    while \"next_page_token\" in resp_json_payload:\n",
    "      time.sleep(3)\n",
    "      page2_token = resp_json_payload[\"next_page_token\"]        \n",
    "      url=\"https://maps.googleapis.com/maps/api/place/textsearch/json?location=\"+\\\n",
    "          str(loc[\"lat\"])+\"%2C\"+str(loc[\"lng\"])+\"&radius=\"+\\\n",
    "          str(r)+\"&type=\"+place+\"&pagetoken=\"+page2_token+\"&key=\"+key\n",
    "      response = requests.get(url)\n",
    "      resp_json_payload = response.json()\n",
    "\n",
    "      df2 = pd.json_normalize(resp_json_payload[\"results\"])\n",
    "      df = pd.concat([df,df2])\n",
    "  return df.drop_duplicates(\"place_id\")\n",
    "\n",
    "def upload2BigQuery(df,table):\n",
    "  new_col = [name.replace(\".\",\"_\") for name in list(df.columns)]\n",
    "  df.set_axis(new_col,axis = 1, inplace = True)\n",
    "  print(\"Upload table:\", table, len(df))\n",
    "  df.to_gbq(dataset+\".\"+table, project_id=project_id, if_exists='replace',progress_bar=True,credentials = credentials)\n",
    "  print(\"Finish upload: \", len(df))\n",
    "\n",
    "def catchData(zip,r,search,check_in, check_out=None):\n",
    "  if check_in:\n",
    "    table_name = \"_\".join([search,str(zip),str(r),check_in])\n",
    "    checkIn = check_in\n",
    "    checkOut = datetime.strptime(checkIn,\"%Y-%m-%d\")+timedelta(days=1)\n",
    "    checkOut = checkOut.strftime(\"%Y-%m-%d\")\n",
    "  else:\n",
    "    today = date.today()\n",
    "    out = today+timedelta(days=1)\n",
    "    checkIn = today.strftime(\"%Y-%m-%d\")\n",
    "    checkOut = out.strftime(\"%Y-%m-%d\")\n",
    "    table_name = \"_\".join([search,str(zip),str(r),checkIn])\n",
    "\n",
    "  if search == \"hotel\":\n",
    "    # df = searchLodging(zip,r)\n",
    "    df, hotel_info = getID(zip,r)\n",
    "    print(\"catchData1\")\n",
    "    print(checkIn, checkOut)\n",
    "    # return\n",
    "    if check_in:\n",
    "      price_df = getAllPrice(df,checkIn, checkOut)\n",
    "    else:\n",
    "      price_df = getAllPrice(df,checkIn, checkOut)\n",
    "\n",
    "    upload2BigQuery(df,table_name)\n",
    "    upload2BigQuery(hotel_info,\"hotel_info\")\n",
    "    upload2BigQuery(price_df,\"HotelPrice_\"+checkIn)\n",
    "\n",
    "  elif search == \"restaurant\":\n",
    "    df = searchFood(zip,r)\n",
    "    print(\"Find restaurant\",len(df))\n",
    "    upload2BigQuery(df,table_name)\n",
    "  elif search == \"play\":\n",
    "    df = searchPlay(zip,r)\n",
    "    upload2BigQuery(df,table_name)\n",
    "  else:\n",
    "    print(\"Wrong searching request, please use: \", searchType)\n",
    "\n",
    "def loadPrice(check_in):\n",
    "#   print(\"load Hotel Price\")\n",
    "  price_dfname = dataset+\".HotelPrice_\"+check_in\n",
    "  query = \"SELECT * FROM `\"+price_dfname+\"`\"\n",
    "\n",
    "  data_frame = pandas_gbq.read_gbq(\n",
    "    query,\n",
    "    project_id=project_id,credentials = credentials)\n",
    "#   print(\"load hotel price 2\")\n",
    "  update_price1 = [int(p.split(\" \")[1][1:].replace(\",\",\"\")) for p in data_frame[\"Price\"]]\n",
    "  data_frame[\"updatePrice\"] = update_price1\n",
    "  \n",
    "  update_roomType = []\n",
    "  update_name = []\n",
    "  update_price = []\n",
    "  for i in range(len(data_frame)):\n",
    "    room_type = data_frame.iloc[i][\"Room_type\"]\n",
    "    name = data_frame.iloc[i][\"name\"]\n",
    "    price = data_frame.iloc[i][\"updatePrice\"]\n",
    "    if \"Suite\" in room_type:\n",
    "      update_roomType.append(\"Suite\")\n",
    "      update_name.append(name)\n",
    "      update_price.append(price)\n",
    "    elif \"King\" in room_type:\n",
    "      update_roomType.append(\"King\")\n",
    "      update_name.append(name)\n",
    "      update_price.append(price)\n",
    "    elif \"Queen\" in room_type:\n",
    "      update_roomType.append(\"Queen\")\n",
    "      update_name.append(name)\n",
    "      update_price.append(price)\n",
    "    elif \"Double\" in room_type:\n",
    "      update_roomType.append(\"Double\")\n",
    "      update_name.append(name)\n",
    "      update_price.append(price)\n",
    "    # else:\n",
    "    #   print(room_type, data_frame.iloc[i][\"Price\"])\n",
    "  update_df = pd.DataFrame({\"name\": update_name, \"Type\":update_roomType, \"Price\": update_price})\n",
    "  update_df = update_df.groupby([\"name\",\"Type\"]).min(\"Price\").reset_index()\n",
    "  return update_df\n",
    "\n",
    "def loadPlace(zip, r, search,check_in):\n",
    "  table_name = \"_\".join([search,str(zip),str(r),check_in])\n",
    "  query = \"SELECT * FROM `\"+dataset+\".\"+table_name+\"`\"\n",
    "  # print(query)\n",
    "  df = pandas_gbq.read_gbq(query,project_id=project_id,credentials = credentials)\n",
    "  # df = pd.read_csv(table_name+\".csv\")\n",
    "  return df\n",
    "\n",
    "def loadData(zip, r, search, check_in):\n",
    "  if search == \"hotel\":\n",
    "    price_df = loadPrice(check_in = check_in)\n",
    "    hotel_df = loadPlace(zip,r,search,check_in = check_in)\n",
    "    return price_df, hotel_df\n",
    "  elif search == \"restaurant\" or search == \"play\":\n",
    "    df = loadPlace(zip,r,search, check_in = check_in)\n",
    "    return None, df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SUzI2ck3bOXR"
   },
   "source": [
    "## Algorithm design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = {\n",
    "    \"price\":{\"no_require\":1, \"high\": -2,\"low\":2},\n",
    "    \"rating\": {\"no_require\": -1, \"high\": -2},\n",
    "    \"safety\": {\"no_require\":1, \"high\":-2} # all feature in same weight\n",
    "}\n",
    "def findOptimalCoef(requirement, items):\n",
    "  coef = {key:[] for key in items}\n",
    "  coef_name = {key:[] for key in items}\n",
    "  bed = None\n",
    "  for item in items:\n",
    "    req = requirement[item]\n",
    "    for key, value in req.items():\n",
    "      if key == \"bed\":\n",
    "        bed = value\n",
    "      elif key == \"rating\":\n",
    "        w = weight[key][value]\n",
    "        coef[item]+=[w,w]\n",
    "        coef_name[item].append(\"_\".join([\"user_rating\",value]))\n",
    "        coef_name[item].append(\"_\".join([\"review_number\",value]))\n",
    "      else:\n",
    "        w = weight[key][value]\n",
    "        coef[item].append(w)\n",
    "        coef_name[item].append(\"_\".join([key,value]))\n",
    "  if \"play\" in coef:\n",
    "    r = coef[\"play\"][0]\n",
    "    safe = coef[\"play\"][-1]\n",
    "    coef[\"twitter\"] = [r,safe]\n",
    "    coef_name[\"twitter\"] = [coef_name[\"play\"][0],coef_name[\"play\"][-1]]\n",
    "  return coef, coef_name, bed\n",
    "\n",
    "def minmax_norm(df):\n",
    "    return (df- df.min()) / (df.max() - df.min())\n",
    "\n",
    "def cleanDF(requirement, items,zip,r,check_in):\n",
    "  output = {}\n",
    "  coef, coef_name, bed = findOptimalCoef(requirement, items)\n",
    "  # load safety data:\n",
    "  safety_df = pd.read_csv(crime_path)[[\"ZIPCODE\",\"safety_level\"]]\n",
    "  safety_df[\"ZIPCODE\"] = safety_df[\"ZIPCODE\"].astype(str)\n",
    "  output[\"safety\"] = safety_df\n",
    "  if \"play\" in items:\n",
    "\n",
    "    twitter_df = pd.read_csv(twitter_path)[[\"acutal_name\",\"zipcode\",\"average_likes\",\"average_reweets\",\"positive_rate\",\"negative_rate\"]]\n",
    "    twitter_df[\"zipcode\"] = twitter_df[\"zipcode\"].astype(str)\n",
    "    twitter_df = twitter_df[twitter_df[\"zipcode\"] == zip]\n",
    "    twitter_df = pd.merge(twitter_df, safety_df, how = \"inner\", left_on = \"zipcode\", right_on = \"ZIPCODE\")\n",
    "    twitter_df[\"rate_gap\"] = twitter_df[\"positive_rate\"] - twitter_df[\"negative_rate\"]\n",
    "\n",
    "    df_input = twitter_df[[\"average_likes\",\"average_reweets\"]]\n",
    "    df_input = minmax_norm(df_input)\n",
    "    twitter_df = pd.concat([twitter_df[[\"acutal_name\",\"rate_gap\",\"safety_level\"]],df_input],axis=1)\n",
    "    twitter_df[\"total\"] = [twitter_df.iloc[t][\"average_likes\"]+twitter_df.iloc[t][\"average_reweets\"]+twitter_df.iloc[t][\"rate_gap\"] for t in range(len(twitter_df))]\n",
    "    twitter_df = twitter_df.fillna(0)\n",
    "    twitter_df[\"Z\"] = twitter_df[[\"total\",\"safety_level\"]].dot(coef[\"twitter\"])\n",
    "\n",
    "    output[\"twitter\"] = twitter_df\n",
    "    # print(twitter_df)\n",
    "\n",
    "  for search in items:\n",
    "    try:\n",
    "      df1, df2 = loadData(zip,r,search,check_in = check_in)\n",
    "    except:\n",
    "      catchData(zip, r, search,check_in = check_in)\n",
    "#       print(\"successful catch: \", search)\n",
    "      df1, df2 = loadData(zip,r,search,check_in = check_in)\n",
    "#       print(\"successful load: \", search)\n",
    "    if search == \"hotel\":\n",
    "      # df1: hotel price\n",
    "      # df2: hotel detail\n",
    "      if bed:\n",
    "        df1= df1[df1[\"Type\"] == bed]\n",
    "      else:\n",
    "        df1 = df1.groupby(\"name\").min(\"Price\").reset_index()\n",
    "\n",
    "      output[\"hotel_price\"]= df1\n",
    "\n",
    "      tmp_hotel = df2[df2[\"business_status\"] == \"OPERATIONAL\"]\n",
    "      tmp_hotel[\"zipcode\"] = [ad.split(\" \")[-1] for ad in tmp_hotel[\"formatted_address\"]]\n",
    "      tmp_hotel = pd.merge(tmp_hotel, safety_df, how = \"inner\", left_on = \"zipcode\", right_on = \"ZIPCODE\")\n",
    "      tmp_hotel = pd.merge(tmp_hotel, df1, how = \"inner\", on = \"name\")\n",
    "      # normalized data\n",
    "      df_input = tmp_hotel[[\"rating\",\"user_ratings_total\",\"safety_level\",\"Price\"]]\n",
    "      df_input = minmax_norm(df_input)\n",
    "      tmp_hotel = pd.concat([tmp_hotel[[\"formatted_address\",\"name\"]],df_input],axis=1)\n",
    "\n",
    "\n",
    "      tmp_hotel[\"Z\"] = tmp_hotel[[\"Price\",\"rating\",\"user_ratings_total\",\"safety_level\"]].dot(coef[\"hotel\"])\n",
    "\n",
    "      output[\"hotel\"] = tmp_hotel\n",
    "    elif search == \"restaurant\":\n",
    "      \n",
    "      tmp_restaurant = df2[df2[\"business_status\"] == \"OPERATIONAL\"]\n",
    "      tmp_restaurant = tmp_restaurant[pd.notnull(tmp_restaurant[\"price_level\"])]\n",
    "\n",
    "      tmp_restaurant[\"zipcode\"] = [ad.split(\" \")[-1] for ad in tmp_restaurant[\"formatted_address\"]]\n",
    "      tmp_restaurant = pd.merge(tmp_restaurant, safety_df, how = \"inner\", left_on = \"zipcode\", right_on = \"ZIPCODE\")\n",
    "\n",
    "      df_input = tmp_restaurant[[\"rating\",\"user_ratings_total\",\"price_level\",\"safety_level\"]]\n",
    "      df_input = minmax_norm(df_input)\n",
    "\n",
    "      tmp_restaurant = pd.concat([tmp_restaurant[[\"formatted_address\",\"name\"]],df_input],axis=1)\n",
    "\n",
    "      tmp_restaurant[\"Z\"] = tmp_restaurant[[\"price_level\",\"rating\",\"user_ratings_total\",\"safety_level\"]].dot(coef[\"restaurant\"])\n",
    "\n",
    "      output[\"restaurant\"] = tmp_restaurant\n",
    "\n",
    "    elif search == \"play\":\n",
    "      tmp_play = df2[df2[\"business_status\"] == \"OPERATIONAL\"]\n",
    "\n",
    "      tmp_play[\"zipcode\"] = [ad.split(\" \")[-1] for ad in tmp_play[\"formatted_address\"]]\n",
    "      tmp_play = pd.merge(tmp_play, safety_df, how = \"inner\", left_on = \"zipcode\", right_on = \"ZIPCODE\")\n",
    "\n",
    "      df_input = tmp_play[[\"rating\",\"user_ratings_total\",\"safety_level\"]]\n",
    "      df_input = minmax_norm(df_input)\n",
    "\n",
    "      tmp_play = pd.concat([tmp_play[[\"formatted_address\",\"name\"]],df_input],axis=1)\n",
    "      tmp_play[\"Z\"] = tmp_play[[\"rating\",\"user_ratings_total\",\"safety_level\"]].dot(coef[\"play\"])\n",
    "\n",
    "      output[\"play\"] = tmp_play\n",
    "  return output\n",
    "\n",
    "def recommendPlace(requirement, items, zip, r, check_in,N):\n",
    "  dfs = cleanDF(requirement, items, zip,r,check_in)\n",
    "  output = {}\n",
    "  for item in items:\n",
    "    # print(key)\n",
    "    df = dfs[item]\n",
    "    min_N = df.nsmallest(N,['Z'])\n",
    "    output[item] = min_N\n",
    "  if \"play\" in items:\n",
    "    df = dfs[\"twitter\"]\n",
    "    min_N = df.nsmallest(N,['Z'])\n",
    "    output[\"twitter\"] = min_N\n",
    "\n",
    "  textfile = open(no_hotel_path, \"w\")\n",
    "  for element in no_hotel_lst:\n",
    "      textfile.write(element + \"\\n\")\n",
    "  textfile.close()\n",
    "  \n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PlaceSearch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
